{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW10\n",
    "## Problem 1: Computational cost \n",
    "\n",
    "Input layer:  $O(d\\cdot k)$  \n",
    "Hidden layer: $ O(k\\cdot k \\cdot (q-1))$  \n",
    "Output layer: $ O(k)$  \n",
    "\n",
    "**In total: $O(d\\cdot k + (q-1)\\cdot k^2) + k) = O(d\\cdot k + (q-1)\\cdot k^2)) $**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Neural networks with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load CIFAR10 train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [00:15<00:00, 10834371.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    ")\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Reducing the size of the training and test accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# car: 1\n",
    "# dog: 5\n",
    "# ship: 8\n",
    "classes = ('plane', 'car', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "trainset = [ex for ex in trainset if ex[1]==1 or ex[1]==5 or ex[1]==8]\n",
    "testset = [ex for ex in testset if ex[1]==1 or ex[1]==5 or ex[1]==8]\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size,shuffle=True)\n",
    "testloader = DataLoader(testset, batch_size=batch_size,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 32, 32])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(trainloader))[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. creat model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=3072, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self,inputdim):\n",
    "        super(Net,self).__init__()\n",
    "        self.fc1 = nn.Linear(inputdim,512)\n",
    "        self.fc2 = nn.Linear(512,1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = torch.flatten(x,1)\n",
    "        x=F.relu(self.fc1(x))\n",
    "        x=self.fc2(2)\n",
    "        return x\n",
    "    \n",
    "net = Net(3*32*32)\n",
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Optimizer and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.paramters(),lr = 1e-3, momentum=0.9)\n",
    "max_epochs = 10\n",
    "\n",
    "for i in range(max_epochs):\n",
    "    for i,data in next(iter(trainloader)):\n",
    "        X,y = data\n",
    "        \n",
    "        # zero the gradient buffer\n",
    "        optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.6063,  0.7648, -1.6090, -0.9929, -0.2790, -0.0833,  1.4728, -0.8165,\n",
       "         -0.0702,  0.7762, -0.7074,  0.0476],\n",
       "        [ 2.3348, -0.0199, -2.6846, -1.6174,  0.9966, -1.1365,  1.2314, -1.7660,\n",
       "          0.9695, -1.6554, -0.1164, -0.1930]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.flatten(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
